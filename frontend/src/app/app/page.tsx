'use client';

import { useState, useRef, useEffect } from 'react';
import { Mic, MicOff, Volume2, Download, Trash2, Search, Filter, ChevronLeft, ChevronRight, Square } from 'lucide-react';
import { useCache, generateAudioHash } from '@/hooks/useCache';
import DrawingHistory from '@/components/DrawingHistory';
import Link from 'next/link';
import { clientLog } from '@/lib/logger';

import { Drawing } from '@/types';

export default function AppPage() {
  const [isRecording, setIsRecording] = useState(false);
  const [audioBlob, setAudioBlob] = useState<Blob | null>(null);
  const [textInput, setTextInput] = useState('');
  const [currentDrawing, setCurrentDrawing] = useState<Drawing | null>(null);
  const [isGenerating, setIsGenerating] = useState(false);
  const [showHistory, setShowHistory] = useState(false);
  const [isProcessingAudio, setIsProcessingAudio] = useState(false);
  const [inputMode, setInputMode] = useState<'voice' | 'text'>('voice');
  const [isPlayingAudio, setIsPlayingAudio] = useState(false);

  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const audioChunksRef = useRef<Blob[]>([]);
  const abortControllerRef = useRef<AbortController | null>(null);
  const currentAudioRef = useRef<HTMLAudioElement | null>(null);
  
  const { getCachedDrawing, setCachedDrawing, getCachedSpeech, setCachedSpeech, clearCache, getCacheStats } = useCache();

  useEffect(() => {
    // è¯·æ±‚éº¦å…‹é£æƒé™å¹¶æ£€æŸ¥éŸ³é¢‘è®¾å¤‡
    const checkAudioDevices = async () => {
      try {
        // æ£€æŸ¥æ˜¯å¦æ”¯æŒgetUserMedia
        if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
          return;
        }
        
        // è·å–éŸ³é¢‘è®¾å¤‡åˆ—è¡¨
        const devices = await navigator.mediaDevices.enumerateDevices();
        const audioInputs = devices.filter(device => device.kind === 'audioinput');
        
        if (audioInputs.length === 0) {
          return;
        }
        
        // è¯·æ±‚éº¦å…‹é£æƒé™
        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
        
        // ç«‹å³åœæ­¢æµä»¥é‡Šæ”¾èµ„æº
        stream.getTracks().forEach(track => track.stop());
        
      } catch (err) {
         console.error('âŒ æ— æ³•è·å–éº¦å…‹é£æƒé™æˆ–æ£€æŸ¥è®¾å¤‡:', err);
         const error = err as Error;
         if (error.name === 'NotAllowedError') {
           console.error('ç”¨æˆ·æ‹’ç»äº†éº¦å…‹é£æƒé™');
         } else if (error.name === 'NotFoundError') {
           console.error('æ²¡æœ‰æ‰¾åˆ°éŸ³é¢‘è¾“å…¥è®¾å¤‡');
         } else if (error.name === 'NotReadableError') {
           console.error('éŸ³é¢‘è®¾å¤‡è¢«å…¶ä»–åº”ç”¨å ç”¨');
         }
       }
    };
    
    checkAudioDevices();
  }, []);

  // ç»„ä»¶å¸è½½æ—¶æ¸…ç†éŸ³é¢‘èµ„æº
  useEffect(() => {
    return () => {
      if (currentAudioRef.current) {
        currentAudioRef.current.pause();
        currentAudioRef.current = null;
      }
    };
  }, []);



  // åˆ›å»ºWAVæ–‡ä»¶å¤´
  const createWavHeader = (sampleRate: number, numChannels: number, numSamples: number) => {
    const buffer = new ArrayBuffer(44);
    const view = new DataView(buffer);
    
    const writeString = (offset: number, string: string) => {
      for (let i = 0; i < string.length; i++) {
        view.setUint8(offset + i, string.charCodeAt(i));
      }
    };
    
    const byteRate = sampleRate * numChannels * 2;
    const blockAlign = numChannels * 2;
    const dataSize = numSamples * numChannels * 2;
    
    writeString(0, 'RIFF');
    view.setUint32(4, 36 + dataSize, true);
    writeString(8, 'WAVE');
    writeString(12, 'fmt ');
    view.setUint32(16, 16, true);
    view.setUint16(20, 1, true); // PCM format
    view.setUint16(22, numChannels, true);
    view.setUint32(24, sampleRate, true);
    view.setUint32(28, byteRate, true);
    view.setUint16(32, blockAlign, true);
    view.setUint16(34, 16, true); // 16-bit
    writeString(36, 'data');
    view.setUint32(40, dataSize, true);
    
    return new Uint8Array(buffer);
  };

  // ä½¿ç”¨Web Audio APIå½•åˆ¶WAVæ ¼å¼éŸ³é¢‘
  const recordWavAudio = async (stream: MediaStream): Promise<Blob> => {
    return new Promise((resolve, reject) => {
      const audioContext = new (window.AudioContext || (window as any).webkitAudioContext)();
      const source = audioContext.createMediaStreamSource(stream);
      const processor = audioContext.createScriptProcessor(4096, 1, 1);
      
      const audioData: Float32Array[] = [];
      
      processor.onaudioprocess = (event) => {
        const inputData = event.inputBuffer.getChannelData(0);
        audioData.push(new Float32Array(inputData));
      };
      
      source.connect(processor);
      processor.connect(audioContext.destination);
      
      // å­˜å‚¨å½•éŸ³æ§åˆ¶å‡½æ•°
      (window as any).stopWavRecording = () => {
        processor.disconnect();
        source.disconnect();
        audioContext.close();
        
        // æ£€æŸ¥éŸ³é¢‘æ•°æ®æ˜¯å¦ä¸ºç©º
        if (audioData.length === 0) {
          reject(new Error('æ²¡æœ‰å½•åˆ¶åˆ°éŸ³é¢‘æ•°æ®'));
          return;
        }
        
        // åˆå¹¶æ‰€æœ‰éŸ³é¢‘æ•°æ®
        const totalLength = audioData.reduce((acc, chunk) => acc + chunk.length, 0);
        
        const combinedData = new Float32Array(totalLength);
        let offset = 0;
        
        for (const chunk of audioData) {
          combinedData.set(chunk, offset);
          offset += chunk.length;
        }
        
        // é‡é‡‡æ ·åˆ°16kHzï¼ˆåç«¯æœŸæœ›çš„é‡‡æ ·ç‡ï¼‰
        const targetSampleRate = 16000;
        const sourceSampleRate = audioContext.sampleRate;
        const resampleRatio = targetSampleRate / sourceSampleRate;
        const resampledLength = Math.floor(combinedData.length * resampleRatio);
        
        const resampledData = new Float32Array(resampledLength);
        for (let i = 0; i < resampledLength; i++) {
          const sourceIndex = i / resampleRatio;
          const index = Math.floor(sourceIndex);
          const fraction = sourceIndex - index;
          
          if (index + 1 < combinedData.length) {
            // çº¿æ€§æ’å€¼
            resampledData[i] = combinedData[index] * (1 - fraction) + combinedData[index + 1] * fraction;
          } else {
            resampledData[i] = combinedData[index] || 0;
          }
        }
        
        // è½¬æ¢ä¸º16ä½PCM
        const pcmData = new Int16Array(resampledData.length);
        for (let i = 0; i < resampledData.length; i++) {
          const sample = Math.max(-1, Math.min(1, resampledData[i]));
          const pcmValue = sample < 0 ? sample * 0x8000 : sample * 0x7FFF;
          pcmData[i] = pcmValue;
        }
        
        // ä½¿ç”¨16kHzé‡‡æ ·ç‡åˆ›å»ºWAVæ–‡ä»¶ï¼ˆä¸åç«¯æœŸæœ›ä¸€è‡´ï¼‰
        const header = createWavHeader(targetSampleRate, 1, resampledData.length);
        
        console.log('éŸ³é¢‘é‡é‡‡æ ·ä¿¡æ¯:', {
          åŸå§‹é‡‡æ ·ç‡: sourceSampleRate + 'Hz',
          ç›®æ ‡é‡‡æ ·ç‡: targetSampleRate + 'Hz',
          åŸå§‹é•¿åº¦: combinedData.length + 'æ ·æœ¬',
          é‡é‡‡æ ·é•¿åº¦: resampledData.length + 'æ ·æœ¬',
          é‡é‡‡æ ·æ¯”ä¾‹: resampleRatio.toFixed(3)
        });
        
        const wavData = new Uint8Array(header.length + pcmData.length * 2);
        wavData.set(header, 0);
        wavData.set(new Uint8Array(pcmData.buffer), header.length);
        
        const wavBlob = new Blob([wavData], { type: 'audio/wav' });
        
        resolve(wavBlob);
      };
    });
  };

  const startRecording = async () => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ 
        audio: {
          echoCancellation: false,
          noiseSuppression: false,
          autoGainControl: false,
          channelCount: 1
        } 
      });
      
      setIsRecording(true);
      
      const recordingPromise = recordWavAudio(stream);
      
      (window as any).currentRecordingPromise = recordingPromise;
      (window as any).currentStream = stream;
      
    } catch (error) {
      console.error('å½•éŸ³å¤±è´¥:', error);
      alert('æ— æ³•å¼€å§‹å½•éŸ³ï¼Œè¯·æ£€æŸ¥éº¦å…‹é£æƒé™');
      setIsRecording(false);
    }
  };

  const stopRecording = async () => {
    if (isRecording && (window as any).stopWavRecording && (window as any).currentRecordingPromise) {
      try {
        (window as any).stopWavRecording();
        
        const wavBlob = await (window as any).currentRecordingPromise;
         setAudioBlob(wavBlob);
         
         if ((window as any).currentStream) {
           (window as any).currentStream.getTracks().forEach((track: MediaStreamTrack) => track.stop());
         }
         
         setIsRecording(false);
         
         // å¯ç”¨è¯­éŸ³è¯†åˆ«
         handleAutoSpeechToDrawing(wavBlob);
         
         (window as any).currentRecordingPromise = null;
         (window as any).currentStream = null;
      } catch (error) {
        console.error('åœæ­¢å½•éŸ³å¤±è´¥:', error);
        setIsRecording(false);
      }
    }
  };



  // è‡ªåŠ¨å¤„ç†è¯­éŸ³è¯†åˆ«å’Œç”Ÿæˆç”»ä½œ
  const handleAutoSpeechToDrawing = async (audioBlob: Blob) => {
    clientLog.info('å¼€å§‹è‡ªåŠ¨è¯­éŸ³è¯†åˆ«å’Œç”»ä½œç”Ÿæˆ');
    setIsProcessingAudio(true);
    
    try {
      // ç”ŸæˆéŸ³é¢‘å“ˆå¸Œ
      const audioHash = await generateAudioHash(audioBlob);
      
      // æ£€æŸ¥ç¼“å­˜
      const cachedResult = getCachedSpeech(audioHash);
      let recognizedText = '';
      
      if (cachedResult) {
        console.log('ä½¿ç”¨ç¼“å­˜çš„è¯­éŸ³è¯†åˆ«ç»“æœ');
        recognizedText = cachedResult;
        setTextInput(recognizedText);
      } else {
        // è¯­éŸ³è¯†åˆ«
        const formData = new FormData();
        formData.append('audio', audioBlob, 'recording.wav');

        const response = await fetch('http://localhost:8000/api/v1/speech/recognize', {
          method: 'POST',
          body: formData,
        });

        if (!response.ok) {
          throw new Error('è¯­éŸ³è¯†åˆ«å¤±è´¥');
        }

        const data = await response.json();
        recognizedText = data.text;
        clientLog.info('è¯­éŸ³è¯†åˆ«æˆåŠŸ', { recognizedText });
        setTextInput(recognizedText);
        
        // å­˜å‚¨åˆ°ç¼“å­˜
        setCachedSpeech(audioHash, recognizedText);
      }
      
      setIsProcessingAudio(false);
      
      // æ£€æŸ¥è¯­éŸ³è¯†åˆ«ç»“æœ
      console.log('è¯­éŸ³è¯†åˆ«ç»“æœ:', recognizedText);
      console.log('éŸ³é¢‘æ–‡ä»¶å¤§å°:', audioBlob.size, 'å­—èŠ‚');
      
      if (!recognizedText.trim() || recognizedText.trim() === 'è¯†åˆ«ç»“æœä¸ºç©º' || recognizedText.trim() === 'æœªèƒ½è¯†åˆ«å‡ºè¯­éŸ³å†…å®¹') {
        alert(`æœªèƒ½è¯†åˆ«åˆ°è¯­éŸ³å†…å®¹ã€‚\néŸ³é¢‘æ–‡ä»¶å¤§å°: ${audioBlob.size} å­—èŠ‚\n\nè¯·ç¡®ä¿ï¼š\n1. å½•éŸ³æ—¶è¯´è¯æ¸…æ™°\n2. å‘¨å›´ç¯å¢ƒå®‰é™\n3. éº¦å…‹é£å·¥ä½œæ­£å¸¸\n4. å½•éŸ³æ—¶é—´è¶³å¤Ÿé•¿ï¼ˆè‡³å°‘2-3ç§’ï¼‰\n\nè¯·é‡æ–°å½•éŸ³æˆ–åˆ‡æ¢åˆ°æ–‡å­—è¾“å…¥æ¨¡å¼ã€‚`);
        return;
      }
      
      // å¦‚æœè¯†åˆ«åˆ°æ–‡å­—ï¼Œè‡ªåŠ¨å¼€å§‹ç”Ÿæˆç”»ä½œ
      await handleGenerateDrawingWithText(recognizedText.trim());
    } catch (error) {
      clientLog.error('è‡ªåŠ¨è¯­éŸ³è¯†åˆ«å¤±è´¥', { error: error instanceof Error ? error.message : String(error) });
      setIsProcessingAudio(false);
      alert('è¯­éŸ³è¯†åˆ«å¤±è´¥ï¼Œè¯·é‡è¯•');
    }
  };

  // æ ¹æ®æ–‡å­—ç”Ÿæˆç”»ä½œ
  const handleGenerateDrawingWithText = async (text: string, forceRefresh: boolean = false) => {
    clientLog.info('å¼€å§‹ç”Ÿæˆç”»ä½œ', { prompt: text, forceRefresh });
    setIsGenerating(true);
    
    // åˆ›å»ºæ–°çš„AbortController
    const abortController = new AbortController();
    abortControllerRef.current = abortController;
    
    try {
      // æš‚æ—¶ç¦ç”¨ç¼“å­˜åŠŸèƒ½ï¼Œæ¯æ¬¡éƒ½è°ƒç”¨å¤§æ¨¡å‹ç”Ÿæˆ
      // if (!forceRefresh) {
      //   const cachedResult = getCachedDrawing(text, 'default');
      //   if (cachedResult) {
      //     console.log('ä½¿ç”¨ç¼“å­˜çš„ç»˜ç”»ç»“æœ');
      //     setCurrentDrawing(cachedResult);
      //     setIsGenerating(false);
      //     return;
      //   }
      // } else {
      //   console.log('å¼ºåˆ¶åˆ·æ–°ï¼Œè·³è¿‡ç¼“å­˜æ£€æŸ¥');
      // }

      const response = await fetch('http://localhost:8001/api/v1/images/generate', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({ 
          prompt: text,
          style: 'ç®€ç¬”ç”»',
          steps: 4
        }),
        signal: abortController.signal,
      });

      if (!response.ok) {
        throw new Error('ç”Ÿæˆç»˜ç”»å¤±è´¥');
      }

      const imageResult = await response.json();
      // è½¬æ¢ä¸ºDrawingæ ¼å¼
      const drawing = {
        id: Date.now(), // ä¸´æ—¶ID
        title: text,
        description: `AIç”Ÿæˆçš„${imageResult.style}`,
        prompt: imageResult.prompt,
        image_url: imageResult.final_image_url,
        step_images: imageResult.step_images,
        style: 'ç®€ç¬”ç”»',
        steps: 4,
        created_at: new Date().toISOString(),
        updated_at: new Date().toISOString()
      };
      clientLog.info('ç”»ä½œç”ŸæˆæˆåŠŸ', { prompt: text, fromCache: false });
      setCurrentDrawing(drawing);
      
      // æš‚æ—¶ç¦ç”¨ç¼“å­˜å­˜å‚¨
      // setCachedDrawing(text, 'default', drawing);
    } catch (error) {
      if (error instanceof Error && error.name === 'AbortError') {
        clientLog.info('ç”»ä½œç”Ÿæˆå·²å–æ¶ˆ', { prompt: text });
        // ä¸æ˜¾ç¤ºé”™è¯¯æç¤ºï¼Œå› ä¸ºæ˜¯ç”¨æˆ·ä¸»åŠ¨å–æ¶ˆ
      } else {
        clientLog.error('ç”Ÿæˆç”»ä½œå¤±è´¥', { error: error instanceof Error ? error.message : String(error), prompt: text });
        alert('ç”Ÿæˆç»˜ç”»å¤±è´¥ï¼Œè¯·é‡è¯•');
      }
    } finally {
      setIsGenerating(false);
      abortControllerRef.current = null;
    }
  };

  const handleSpeechRecognition = async () => {
    if (!audioBlob) return;

    clientLog.info('å¼€å§‹è¯­éŸ³è¯†åˆ«');
    setIsProcessingAudio(true);
    try {
      // ç”ŸæˆéŸ³é¢‘å“ˆå¸Œ
      const audioHash = await generateAudioHash(audioBlob);
      
      // æ£€æŸ¥ç¼“å­˜
      const cachedResult = getCachedSpeech(audioHash);
      if (cachedResult) {
        console.log('ä½¿ç”¨ç¼“å­˜çš„è¯­éŸ³è¯†åˆ«ç»“æœ');
        setTextInput(cachedResult);
        setIsProcessingAudio(false);
        return;
      }

      const formData = new FormData();
      formData.append('audio', audioBlob, 'recording.wav');

      const response = await fetch('http://localhost:8000/api/v1/speech/recognize', {
        method: 'POST',
        body: formData,
      });

      if (!response.ok) {
        throw new Error('è¯­éŸ³è¯†åˆ«å¤±è´¥');
      }

      const data = await response.json();
      clientLog.info('è¯­éŸ³è¯†åˆ«æˆåŠŸ', { recognizedText: data.text });
      setTextInput(data.text);
      
      // å­˜å‚¨åˆ°ç¼“å­˜
      setCachedSpeech(audioHash, data.text);
    } catch (error) {
      clientLog.error('è¯­éŸ³è¯†åˆ«å¤±è´¥', { error: error instanceof Error ? error.message : String(error) });
      alert('è¯­éŸ³è¯†åˆ«å¤±è´¥ï¼Œè¯·é‡è¯•');
    } finally {
      setIsProcessingAudio(false);
    }
  };

  const generateDrawingInternal = async (forceRefresh: boolean = false) => {
    if (!textInput.trim()) {
      alert('è¯·è¾“å…¥æè¿°æˆ–å½•åˆ¶è¯­éŸ³');
      return;
    }

    clientLog.info('å¼€å§‹ç”Ÿæˆç”»ä½œ', { prompt: textInput, forceRefresh });
    setIsGenerating(true);
    
    // åˆ›å»ºæ–°çš„AbortController
    const abortController = new AbortController();
    abortControllerRef.current = abortController;
    
    try {
      // æš‚æ—¶ç¦ç”¨ç¼“å­˜åŠŸèƒ½ï¼Œæ¯æ¬¡éƒ½è°ƒç”¨å¤§æ¨¡å‹ç”Ÿæˆ
      // if (!forceRefresh) {
      //   const cachedResult = getCachedDrawing(textInput.trim(), 'default');
      //   if (cachedResult) {
      //     console.log('ä½¿ç”¨ç¼“å­˜çš„ç»˜ç”»ç»“æœ');
      //     setCurrentDrawing(cachedResult);
      //     setIsGenerating(false);
      //     return;
      //   }
      // } else {
      //   console.log('å¼ºåˆ¶åˆ·æ–°ï¼Œè·³è¿‡ç¼“å­˜æ£€æŸ¥');
      // }

      const response = await fetch('http://localhost:8001/api/v1/images/generate', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({ 
          prompt: textInput,
          style: 'ç®€ç¬”ç”»',
          steps: 4
        }),
        signal: abortController.signal,
      });

      if (!response.ok) {
        throw new Error('ç”Ÿæˆç»˜ç”»å¤±è´¥');
      }

      const imageResult = await response.json();
      // è½¬æ¢ä¸ºDrawingæ ¼å¼
      const drawing = {
        id: Date.now(), // ä¸´æ—¶ID
        title: textInput,
        description: `AIç”Ÿæˆçš„${imageResult.style}`,
        prompt: imageResult.prompt,
        image_url: imageResult.final_image_url,
        step_images: imageResult.step_images,
        style: 'ç®€ç¬”ç”»',
        steps: 4,
        created_at: new Date().toISOString(),
        updated_at: new Date().toISOString()
      };
      clientLog.info('ç”»ä½œç”ŸæˆæˆåŠŸ', { prompt: textInput, fromCache: false });
      setCurrentDrawing(drawing);
      
      // æš‚æ—¶ç¦ç”¨ç¼“å­˜å­˜å‚¨
      // setCachedDrawing(textInput.trim(), 'default', drawing);
    } catch (error) {
      if (error instanceof Error && error.name === 'AbortError') {
        clientLog.info('ç”»ä½œç”Ÿæˆå·²å–æ¶ˆ', { prompt: textInput });
        // ä¸æ˜¾ç¤ºé”™è¯¯æç¤ºï¼Œå› ä¸ºæ˜¯ç”¨æˆ·ä¸»åŠ¨å–æ¶ˆ
      } else {
        clientLog.error('ç”Ÿæˆç”»ä½œå¤±è´¥', { error: error instanceof Error ? error.message : String(error), prompt: textInput });
        alert('ç”Ÿæˆç»˜ç”»å¤±è´¥ï¼Œè¯·é‡è¯•');
      }
    } finally {
      setIsGenerating(false);
      abortControllerRef.current = null;
    }
  };

  const handleGenerateDrawing = () => generateDrawingInternal(false);
  const handleForceRefresh = () => generateDrawingInternal(true);
  
  const handleStopGeneration = () => {
    if (abortControllerRef.current) {
      abortControllerRef.current.abort();
      clientLog.info('ç”¨æˆ·å–æ¶ˆç”»ä½œç”Ÿæˆ');
    }
  };

  const playAudio = async () => {
    if (!audioBlob) {
      console.warn('âŒ æ²¡æœ‰å¯æ’­æ”¾çš„éŸ³é¢‘');
      return;
    }

    console.log('ğŸ”Š å‡†å¤‡æ’­æ”¾éŸ³é¢‘');
    console.log('ğŸ“ éŸ³é¢‘æ–‡ä»¶ä¿¡æ¯:', {
      size: audioBlob.size + ' å­—èŠ‚',
      type: audioBlob.type,
      lastModified: new Date().toISOString()
    });

    try {
      // æ£€æŸ¥éŸ³é¢‘æ–‡ä»¶å†…å®¹
      const arrayBuffer = await audioBlob.arrayBuffer();
      const uint8Array = new Uint8Array(arrayBuffer);
      
      // æ£€æŸ¥éŸ³é¢‘æ•°æ®éƒ¨åˆ†æ˜¯å¦æœ‰å†…å®¹
      const audioDataStart = 44; // WAVæ–‡ä»¶å¤´é€šå¸¸æ˜¯44å­—èŠ‚
      const audioDataBytes = uint8Array.slice(audioDataStart);
      const nonZeroBytes = audioDataBytes.filter(b => b !== 0).length;
      
      if (nonZeroBytes === 0) {
        alert('å½•åˆ¶çš„éŸ³é¢‘æ–‡ä»¶ä¸ºç©ºï¼Œè¯·æ£€æŸ¥éº¦å…‹é£æ˜¯å¦æ­£å¸¸å·¥ä½œ');
        return;
      }

      // å¦‚æœå½“å‰æœ‰éŸ³é¢‘åœ¨æ’­æ”¾ï¼Œå…ˆåœæ­¢
      if (currentAudioRef.current) {
        currentAudioRef.current.pause();
        currentAudioRef.current = null;
      }

      setIsPlayingAudio(true);
      const audioUrl = URL.createObjectURL(audioBlob);
      
      const audio = new Audio(audioUrl);
      currentAudioRef.current = audio;

      audio.onended = () => {
        setIsPlayingAudio(false);
        URL.revokeObjectURL(audioUrl);
        currentAudioRef.current = null;
      };

      audio.onerror = (error) => {
        setIsPlayingAudio(false);
        URL.revokeObjectURL(audioUrl);
        currentAudioRef.current = null;
        alert('éŸ³é¢‘æ’­æ”¾å¤±è´¥ï¼Œè¯·é‡è¯•');
      };

      audio.onpause = () => {
        setIsPlayingAudio(false);
      };

      await audio.play();
    } catch (error) {
      setIsPlayingAudio(false);
      alert('æ— æ³•æ’­æ”¾éŸ³é¢‘ï¼Œè¯·æ£€æŸ¥æµè§ˆå™¨è®¾ç½®');
    }
  };

  const stopAudio = () => {
    if (currentAudioRef.current) {
      currentAudioRef.current.pause();
      currentAudioRef.current = null;
      setIsPlayingAudio(false);
    }
  };

  // ç”Ÿæˆæµ‹è¯•éŸ³é¢‘æ–‡ä»¶
  const generateTestAudio = () => {
    // ç”Ÿæˆ1ç§’çš„440Hzæ­£å¼¦æ³¢ï¼ˆAéŸ³ï¼‰
    const sampleRate = 16000;
    const duration = 1; // 1ç§’
    const frequency = 440; // AéŸ³
    const samples = sampleRate * duration;
    
    // åˆ›å»ºéŸ³é¢‘æ•°æ®
    const audioData = new Float32Array(samples);
    for (let i = 0; i < samples; i++) {
      audioData[i] = Math.sin(2 * Math.PI * frequency * i / sampleRate) * 0.3; // 30%éŸ³é‡
    }
    
    // è½¬æ¢ä¸º16ä½PCM
    const pcmData = new Int16Array(audioData.length);
    for (let i = 0; i < audioData.length; i++) {
      const sample = Math.max(-1, Math.min(1, audioData[i]));
      pcmData[i] = sample < 0 ? sample * 0x8000 : sample * 0x7FFF;
    }
    
    // åˆ›å»ºWAVæ–‡ä»¶å¤´
    const createWavHeader = (sampleRate: number, channels: number, samples: number) => {
      const buffer = new ArrayBuffer(44);
      const view = new DataView(buffer);
      
      // RIFF header
      view.setUint32(0, 0x46464952, true); // "RIFF"
      view.setUint32(4, 36 + samples * 2, true); // file size
      view.setUint32(8, 0x45564157, true); // "WAVE"
      
      // fmt chunk
      view.setUint32(12, 0x20746d66, true); // "fmt "
      view.setUint32(16, 16, true); // chunk size
      view.setUint16(20, 1, true); // PCM format
      view.setUint16(22, channels, true); // channels
      view.setUint32(24, sampleRate, true); // sample rate
      view.setUint32(28, sampleRate * channels * 2, true); // byte rate
      view.setUint16(32, channels * 2, true); // block align
      view.setUint16(34, 16, true); // bits per sample
      
      // data chunk
      view.setUint32(36, 0x61746164, true); // "data"
      view.setUint32(40, samples * 2, true); // data size
      
      return new Uint8Array(buffer);
    };
    
    // åˆ›å»ºWAVæ–‡ä»¶
    const header = createWavHeader(sampleRate, 1, audioData.length);
    const wavData = new Uint8Array(header.length + pcmData.length * 2);
    wavData.set(header, 0);
    wavData.set(new Uint8Array(pcmData.buffer), header.length);
    
    const testBlob = new Blob([wavData], { type: 'audio/wav' });
    
    setAudioBlob(testBlob);
  };

  const downloadImage = () => {
    if (currentDrawing && currentDrawing.image_url) {
      const link = document.createElement('a');
      link.href = currentDrawing.image_url;
      link.download = `babydraw-${currentDrawing.id}.png`;
      document.body.appendChild(link);
      link.click();
      document.body.removeChild(link);
    }
  };

  const clearAll = () => {
    setTextInput('');
    setAudioBlob(null);
    stopAudio(); // åœæ­¢æ­£åœ¨æ’­æ”¾çš„éŸ³é¢‘
    setCurrentDrawing(null);
  };

  return (
    <div className="min-h-screen bg-gradient-to-br from-purple-100 via-pink-50 to-blue-100">
      {/* é¡¶éƒ¨å¯¼èˆª */}
      <div className="bg-white/80 backdrop-blur-sm border-b border-purple-200 sticky top-0 z-10">
        <div className="max-w-6xl mx-auto px-4 py-4 flex items-center justify-between">
          <Link href="/" className="flex items-center space-x-3 hover:scale-105 transition-transform cursor-pointer">
            <div className="w-10 h-10 bg-gradient-to-r from-purple-500 to-pink-500 rounded-full flex items-center justify-center">
              <span className="text-white font-bold text-lg">ğŸ¨</span>
            </div>
            <h1 className="text-2xl font-bold bg-gradient-to-r from-purple-600 to-pink-600 bg-clip-text text-transparent">
              BabyDraw
            </h1>
          </Link>
          
          <div className="flex items-center space-x-4">
            <button
              onClick={() => setShowHistory(!showHistory)}
              className="px-4 py-2 bg-purple-500 text-white rounded-lg hover:bg-purple-600 transition-colors flex items-center space-x-2"
            >
              <span>ğŸ“š</span>
              <span>å†å²è®°å½•</span>
            </button>
            <button
              onClick={() => {
                console.log('æ¸…é™¤ç¼“å­˜æŒ‰é’®è¢«ç‚¹å‡»');
                clearCache();
              }}
              className="px-4 py-2 bg-gray-500 text-white rounded-lg hover:bg-gray-600 transition-colors flex items-center space-x-2"
            >
              <Trash2 className="w-4 h-4" />
              <span>æ¸…é™¤ç¼“å­˜</span>
            </button>
          </div>
        </div>
      </div>

      <div className="max-w-6xl mx-auto px-4 py-8">
        {showHistory ? (
          <DrawingHistory />
        ) : (
          <div className="space-y-8">
            {/* ç”»å¸ƒåŒºåŸŸ - é¡¶éƒ¨ */}
            <div className="bg-white/70 backdrop-blur-sm rounded-2xl p-6 shadow-lg border border-purple-200">
              <h2 className="text-xl font-semibold text-gray-800 mb-4 flex items-center">
                ğŸ–¼ï¸ ç”»å¸ƒ
              </h2>
              
              <div className="aspect-video bg-gradient-to-br from-purple-50 to-pink-50 rounded-lg border-2 border-dashed border-purple-300 flex items-center justify-center relative overflow-hidden">
                {isGenerating ? (
                  <div className="text-center">
                    <div className="w-16 h-16 border-4 border-purple-500 border-t-transparent rounded-full animate-spin mx-auto mb-4"></div>
                    <p className="text-purple-600 font-medium">AIæ­£åœ¨åˆ›ä½œä¸­...</p>
                  </div>
                ) : currentDrawing ? (
                  <div className="w-full h-full relative group">
                    <img 
                      src={currentDrawing.image_url || ''} 
                      alt={currentDrawing.prompt}
                      className="w-full h-full object-contain rounded-lg"
                    />
                    <div className="absolute inset-0 bg-black/50 opacity-0 group-hover:opacity-100 transition-opacity flex items-center justify-center space-x-4">
                      <button
                        onClick={downloadImage}
                        className="p-3 bg-white/20 backdrop-blur-sm text-white rounded-lg hover:bg-white/30 transition-colors"
                      >
                        <Download className="w-6 h-6" />
                      </button>
                    </div>
                  </div>
                ) : (
                  <div className="text-center text-gray-500">
                    <div className="text-6xl mb-4">ğŸ¨</div>
                    <p className="text-lg font-medium">ç­‰å¾…åˆ›ä½œ...</p>
                    <p className="text-sm">å½•åˆ¶è¯­éŸ³åå°†è‡ªåŠ¨å¼€å§‹ä½œç”»ï¼Œæˆ–åˆ‡æ¢åˆ°æ–‡å­—è¾“å…¥æ¨¡å¼</p>
                  </div>
                )}
              </div>
              
              {currentDrawing && (
                <div className="mt-4 p-4 bg-purple-50 rounded-lg">
                  <p className="text-sm text-gray-700">
                    <strong>æè¿°ï¼š</strong>{currentDrawing.prompt}
                  </p>
                  <p className="text-xs text-gray-500 mt-1">
                    åˆ›å»ºæ—¶é—´ï¼š{new Date(currentDrawing.created_at).toLocaleString()}
                  </p>
                </div>
              )}
            </div>

            {/* è¾“å…¥åŒºåŸŸ - åº•éƒ¨ */}
            <div className="bg-white/70 backdrop-blur-sm rounded-2xl p-6 shadow-lg border border-purple-200">
              <h2 className="text-xl font-semibold text-gray-800 mb-4 flex items-center">
                ğŸ’¬ è¾“å…¥æ–¹å¼
              </h2>
              
              {/* è¾“å…¥æ¨¡å¼åˆ‡æ¢ */}
              <div className="flex bg-gray-100 rounded-lg p-1 mb-6">
                <button
                  onClick={() => setInputMode('voice')}
                  className={`flex-1 flex items-center justify-center gap-2 py-2 px-4 rounded-md transition-all ${
                    inputMode === 'voice' 
                      ? 'bg-white text-purple-600 shadow-sm' 
                      : 'text-gray-600 hover:text-gray-900'
                  }`}
                >
                  <Mic className="w-4 h-4" />
                  è¯­éŸ³è¾“å…¥
                </button>
                <button
                  onClick={() => setInputMode('text')}
                  className={`flex-1 flex items-center justify-center gap-2 py-2 px-4 rounded-md transition-all ${
                    inputMode === 'text' 
                      ? 'bg-white text-purple-600 shadow-sm' 
                      : 'text-gray-600 hover:text-gray-900'
                  }`}
                >
                  âœï¸ æ–‡å­—è¾“å…¥
                </button>
              </div>

              {/* è¯­éŸ³è¾“å…¥ç•Œé¢ */}
              {inputMode === 'voice' && (
                <div className="space-y-4">
                  <div className="flex items-center justify-center space-x-4">
                    <button
                      onClick={isRecording ? stopRecording : startRecording}
                      className={`w-20 h-20 rounded-full flex items-center justify-center transition-all transform hover:scale-105 ${
                        isRecording 
                          ? 'bg-red-500 hover:bg-red-600 animate-pulse' 
                          : 'bg-purple-500 hover:bg-purple-600'
                      }`}
                    >
                      {isRecording ? (
                        <MicOff className="w-10 h-10 text-white" />
                      ) : (
                        <Mic className="w-10 h-10 text-white" />
                      )}
                    </button>
                    

                  </div>
                  

                  
                  <p className="text-center text-gray-600">
                    {isRecording 
                      ? 'ğŸ”´ æ­£åœ¨å½•éŸ³ï¼Œå†æ¬¡ç‚¹å‡»åœæ­¢å¹¶å¼€å§‹ä½œç”»' 
                      : isProcessingAudio 
                        ? 'ğŸ¯ æ­£åœ¨è¯†åˆ«è¯­éŸ³å¹¶ç”Ÿæˆç”»ä½œ...' 
                        : isGenerating 
                          ? 'ğŸ¨ AIæ­£åœ¨åˆ›ä½œä¸­...' 
                          : 'ç‚¹å‡»éº¦å…‹é£å¼€å§‹å½•éŸ³ï¼Œå½•éŸ³ç»“æŸåå°†è‡ªåŠ¨å¼€å§‹ä½œç”»'
                    }
                  </p>
                  
                  {audioBlob && !isProcessingAudio && !isGenerating && (
                    <div className="flex justify-center space-x-2">
                      {!isPlayingAudio ? (
                        <button
                          onClick={playAudio}
                          className="px-4 py-2 bg-green-500 text-white rounded-lg hover:bg-green-600 transition-colors flex items-center space-x-2"
                        >
                          <Volume2 className="w-4 h-4" />
                          <span>æ’­æ”¾å½•éŸ³</span>
                        </button>
                      ) : (
                        <button
                          onClick={stopAudio}
                          className="px-4 py-2 bg-red-500 text-white rounded-lg hover:bg-red-600 transition-colors flex items-center space-x-2 animate-pulse"
                        >
                          <Square className="w-4 h-4" />
                          <span>åœæ­¢æ’­æ”¾</span>
                        </button>
                      )}
                      <button
                        onClick={generateTestAudio}
                        className="px-4 py-2 bg-blue-500 text-white rounded-lg hover:bg-blue-600 transition-colors flex items-center space-x-2"
                      >
                        ğŸ”§ æµ‹è¯•éŸ³é¢‘
                      </button>
                    </div>
                  )}
                  
                  {!audioBlob && !isProcessingAudio && !isGenerating && (
                    <div className="flex justify-center">
                      <button
                        onClick={generateTestAudio}
                        className="px-4 py-2 bg-blue-500 text-white rounded-lg hover:bg-blue-600 transition-colors flex items-center space-x-2"
                      >
                        ğŸ”§ ç”Ÿæˆæµ‹è¯•éŸ³é¢‘
                      </button>
                    </div>
                  )}
                  
                  {(isProcessingAudio || isGenerating) && (
                    <div className="flex justify-center">
                      <div className="w-8 h-8 border-4 border-purple-500 border-t-transparent rounded-full animate-spin"></div>
                    </div>
                  )}
                </div>
              )}

              {/* æ–‡å­—è¾“å…¥ç•Œé¢ */}
              {inputMode === 'text' && (
                <div className="space-y-4">
                  <textarea
                    value={textInput}
                    onChange={(e) => setTextInput(e.target.value)}
                    placeholder="æè¿°ä½ æƒ³è¦çš„ç”»é¢ï¼Œæ¯”å¦‚ï¼šä¸€åªå¯çˆ±çš„å°çŒ«åœ¨èŠ±å›­é‡Œç©è€"
                    className="w-full h-32 p-4 border border-purple-200 rounded-lg resize-none focus:outline-none focus:ring-2 focus:ring-purple-500 bg-white/50"
                  />
                </div>
              )}

              {/* è¯†åˆ«ç»“æœæ˜¾ç¤º */}
              {textInput && (
                <div className="mt-4 p-4 bg-blue-50 border border-blue-200 rounded-lg">
                  <p className="text-sm text-blue-800 font-medium mb-1">å½“å‰æè¿°ï¼š</p>
                  <p className="text-blue-900">{textInput}</p>
                </div>
              )}

              {/* æ“ä½œæŒ‰é’® */}
              <div className="flex justify-between items-center mt-6">
                <button
                  onClick={clearAll}
                  className="px-4 py-2 bg-gray-500 text-white rounded-lg hover:bg-gray-600 transition-colors flex items-center space-x-2"
                >
                  <Trash2 className="w-4 h-4" />
                  <span>æ¸…ç©º</span>
                </button>
                
                {isGenerating ? (
                  <button
                    onClick={handleStopGeneration}
                    className="px-8 py-3 bg-red-500 text-white rounded-lg hover:bg-red-600 transition-all flex items-center space-x-2 text-lg font-semibold"
                  >
                    <Square className="w-5 h-5" />
                    <span>åœæ­¢ä½œç”»</span>
                  </button>
                ) : (
                  <button
                    onClick={handleGenerateDrawing}
                    disabled={!textInput.trim()}
                    className="px-8 py-3 bg-gradient-to-r from-purple-500 to-pink-500 text-white rounded-lg hover:from-purple-600 hover:to-pink-600 transition-all disabled:opacity-50 disabled:cursor-not-allowed flex items-center space-x-2 text-lg font-semibold"
                  >
                    <span>ğŸ¨</span>
                    <span>ç”Ÿæˆç”»ä½œ</span>
                   </button>
                 )}
               </div>
            </div>
          </div>
        )}
      </div>
    </div>
  );
}